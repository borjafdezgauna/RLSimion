<RLSimion FileVersion="1.3.3">
<RLSimion>
  <Offline-Training-File></Offline-Training-File>
  <Log>
    <Num-Functions-Logged>10</Num-Functions-Logged>
    <Log-Freq>0.25</Log-Freq>
    <Log-Eval-Episodes>true</Log-Eval-Episodes>
    <Log-Training-Episodes>false</Log-Training-Episodes>
    <Log-Functions>true</Log-Functions>
  </Log>
  <World>
    <Num-Integration-Steps>4</Num-Integration-Steps>
    <Delta-T>0.25</Delta-T>
    <Dynamic-Model>
      <Model>
        <Rain-car>
        </Rain-car>
        </Model>
    </Dynamic-Model>
  </World>
  <Experiment>
    <Random-Seed>1</Random-Seed>
    <Num-Episodes>100</Num-Episodes>
    <Eval-Freq>5</Eval-Freq>
    <Progress-Update-Freq>1.0</Progress-Update-Freq>
    <Episode-Length>100</Episode-Length>
  </Experiment>
  <SimGod>
    <Target-Function-Update-Freq>100</Target-Function-Update-Freq>
    <Gamma>0.9</Gamma>
    <Freeze-Target-Function>false</Freeze-Target-Function>
    <Use-Importance-Weights>false</Use-Importance-Weights>
    <Experience-Replay>
      <Buffer-Size>1000</Buffer-Size>
      <Update-Batch-Size>10</Update-Batch-Size>
    </Experience-Replay>
    <Simion>
      <Type>
        <Double-DQN>
          <Q-Network>
            <Num-Action-Steps>11</Num-Action-Steps>
            <Input-State>
              <Input-State>position</Input-State>
            </Input-State>
            <Input-State>
              <Input-State>velocity</Input-State>
            </Input-State>
            <Output-Action>
              <Output-Action>acceleration</Output-Action>
            </Output-Action>
            <Minibatch-Size>100</Minibatch-Size>
            <Use-Normalization>false</Use-Normalization>
            <Learner>
              <Learner-Type>
                <SGD>
                  <Learning-Rate>
                    <Schedule>
                      <Simple-Linear-Decay>
                        <Initial-Value>0.0001</Initial-Value>
                        <End-Value>0.000000000001</End-Value>
                      </Simple-Linear-Decay>
                      </Schedule>
                  </Learning-Rate>
                </SGD>
                </Learner-Type>
            </Learner>
            <Layers>
              <Num-Units>100</Num-Units>
              <Activation>ReLU</Activation>
            </Layers>
            <Layers>
              <Num-Units>100</Num-Units>
              <Activation>ReLU</Activation>
            </Layers>
          </Q-Network>
          <Policy>
            <Policy>
              <Noise-Plus-Greedy-Policy>
                <Exploration-Noise>
                  <Noise>
                    <Ornstein-Uhlenbeck>
                      <Mu>0.0</Mu>
                      <Sigma>1.0</Sigma>
                      <Theta>0.1</Theta>
                      <Scale>
                        <Schedule>
                          <Simple-Linear-Decay>
                            <Initial-Value>1.0</Initial-Value>
                            <End-Value>0.01</End-Value>
                          </Simple-Linear-Decay>
                          </Schedule>
                      </Scale>
                    </Ornstein-Uhlenbeck>
                    </Noise>
                </Exploration-Noise>
              </Noise-Plus-Greedy-Policy>
              </Policy>
          </Policy>
        </Double-DQN>
        </Type>
    </Simion>
  </SimGod>
</RLSimion>
</RLSimion>
